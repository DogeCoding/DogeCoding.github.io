title: 视频开发
tags: iOS
---

> - **软解码和硬解码**
> GPU解码就是所谓的硬解码，CPU解码就是软解码。iOS提供的播放器类使用的是硬解码，所以视频播放对CPU不会有很大的压力，但是支持的播放格式比较单一，一般就是MP4、MOV、M4V这几个。
> - **HTTP Live Streaming**
> HTTP Live Streaming（缩写是 HLS）是一个由苹果公司提出的基于HTTP的流媒体网络传输协议。它的工作原理是把整个流分成一个个小的基于HTTP的文件来下载，每次只下载一些。当媒体流正在播放时，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。支持的视频流编码为H.264。我们在视频网站上看到的M3U8后缀的播放链接就是使用HLS协议的视频。HLS优点，1、看完一段缓存一段，防止只看一段视频但是把整个视频文件都缓存下来的用户，减少服务器压力和节省流量。2、根据用户网速切换不同的码率，兼顾流程性和清晰度。

# 播放
实现视频播放的两个方案。
***

## 一、自己实现对数据编码解码
可以在一些开源播放器上进行二次开发，如Bilibili的[ijkplayer](https://github.com/Bilibili/ijkplayer)，或者直接对[FFmpeg](https://github.com/FFmpeg/FFmpeg)开发，优点在整个播放过程可控，为后续进行缓存、流量控制、码率切换等开发提供了基础，缺点是复杂，要求高，工程量大。
***

## 二、AVFoundation
Media Assets, Playback and Editing. 使用Apple自有框架。

### AVAsset
> AVAsset is an abstract, immutable class used to model timed audiovisual media such as videos and sounds. An asset may contain one or more tracks that are intended to be presented or processed together, each of a uniform media type, including but not limited to audio, video, text, closed captions, and subtitles.

Audiovisual media的资源类，通常通过`AVURLAsset`用URL来实例化，可以用[Atom Inspector](https://developer.apple.com/download/more/)(一个Apple提供的用来查看视频信息的工具)来观察一个视频的属性，再去`AVAsset`中对应其属性。

| AVAsset属性 | 视频文件属性 |
| --- | --- |
| duration: CMTime | duration, timescale时长和时间尺度 |
| preferredRate: Float | 默认速度 |
| preferredVolume: Float | 默认音量 |
| creationDate: AVMetadataItem? | 视频创建时间 |
| tracks: [AVAssetTrack] | 轨道 |
| trackGroups: [AVAssetTrackGroup] | 轨道组 |
| lyrics: String? | 当前语言环境合适的歌词 |
| metadata: [AVMetadataItem] | 元数据 |


### AVPlayer
> An AVPlayer is a controller object used to manage the playback and timing of a media asset. It provides the interface to control the player’s transport behavior such as its ability to play, pause, change the playback rate, and seek to various points in time within the media’s timeline. You can use an AVPlayer to play local and remote file-based media, such as QuickTime movies and MP3 audio files, as well as audiovisual media served using HTTP Live Streaming.

AVPlayer是一个控制对象用于管理媒体asset的播放，它提供了相关的接口控制播放器的行为，比如：播放、暂停、改变播放的速率、跳转到媒体时间轴上的某一个点（简单理解就是实现拖动功能显示对应的视频位置内容）。我们能够使用AVPlayer播放本地和远程的媒体文件（使用 HTTP Live Streaming），比如： QuickTime movies 和 MP3 audio files，所以AVPlayer可以满足音视频播放的基本需求。
![AVFoundation的层次](http://oo8snaf4x.bkt.clouddn.com/15009677046266.png?imageView2/0/q/100)

### AVPlayerItem
> AVPlayerItem models the timing and presentation state of an asset played by an AVPlayer object. It provides the interface to seek to various times in the media, determine its presentation size, identify its current time, and much more. 

`AVPlayerItem`是一个负责处理`AVAsset`的资源并通过`AVPlayer`来播放的载体，提供了`seek`、确定显示大小、ID、时间等的接口。

### AVPlayerLayer
> AVPlayerLayer is a subclass of CALayer to which an AVPlayer object can direct its visual output. It can be used as the backing layer for a UIView or NSView or can be manually added to the layer hierarchy to present your video content on screen.

负责`AVPlayer`的视频输出展示。

![依赖关系图](http://oo8snaf4x.bkt.clouddn.com/15012312808745.png?imageView2/0/q/100)


### 简单使用

``` //
class AVPlayerTestView: UIView {
    let view: UIView? = nil
    func initPlayerView() {
        guard let url = URL.init(string: "http://lavaweb-10015286.video.myqcloud.com/%E5%B0%BD%E6%83%85LAVA.mp4") else { return }
        let asset = AVAsset.init(url: url)
        let item = AVPlayerItem.init(asset: asset)
        let player = AVPlayer.init(playerItem: item)
        let playerLayer = AVPlayerLayer.init(layer: player)
        view?.layer.addSublayer(playerLayer)
    }
}
```

设置好一个`AVPlayer`的依赖关系和输出图层后，`AVPlayerItem`会根据你的URL去请求数据，自己内部做缓冲然后播放。我们需要做的是用KVO监听`AVPlayerItem`内部几个关键属性的状态，然后做出我们的处理。

| AVPlayerItem属性 | 状态 |
| --- | --- |
| status: AVPlayerItemStatus |  |
| .unknown: AVPlayerItemStatus | 未知状态 |
| .readyToPlay: AVPlayerItemStatus | 准备好去播放 |
| .failed: AVPlayerItemStatus | 资源无法被播放 |
| loadedTimeRanges: [NSValue] | 加载了的资源的时间范围(一般用来更新缓冲UI) |
| playbackBufferEmpty: Bool | 没有缓冲数据 |
| playbackLikelyToKeepUp: Bool | 有足够的缓冲大致能播放无卡顿 |

> General State Observations: You can use Key-value observing (KVO) to observe state changes to many of the player’s dynamic properties, such as its currentItem or its playback rate. You should register and unregister for KVO change notifications on the main thread. This avoids the possibility of receiving a partial notification if a change is being made on another thread. AVFoundation invokes observeValue(forKeyPath:of:change:context:) on the main thread, even if the change operation is made on another thread.
>  ***
> 基本状态观察者：你能够使用KVO来观察player动态属性的状态改变，比如像： currentItem 或者它的播放速度。我们应该在主线程注册和去除KVO，这能够避免如果在其它线程发送改变而导致接收局部通知，当发生通知，AVFoundation将在主线程调用observeValue(forKeyPath:of:change:context:) 方法，即使是在其他线程发生。

KVO能够很好的观察生成的状态，但是并不能够观察播放时间的改变，所以AVPlayer提供了两个方法来观察时间的改变:

``` //
/*
    @param interval
    调用block的时间间隔
    @param queue
    推荐使用串行队列，放在主线程就行了，并行队列会产生不明确的结果
*/
func addPeriodicTimeObserver(forInterval interval: CMTime, queue: DispatchQueue?, using block: @escaping (CMTime) -> Void) -> Any {
    // 可以在里面去设置控制状态，刷新进度UI
}

func addBoundaryTimeObserver(forTimes times: [NSValue], queue: DispatchQueue?, using block: @escaping () -> Void) -> Any
```


> Tips:
> 
> - 创建多个`AVPlayerLayer`只有最近的layer才会显示视频帧
> - 可以创建多个`AVPlayerItem`来替换`AVPlayer`的当前item，`func replaceCurrentItem(with item: AVPlayerItem?)`
> - 监听后要注意控制监听的生命周期

# 缓存
Apple自有的框架是没有提供缓存功能的，`AVPlayer`也没有提供直接获取其下载数据的接口，所以想做缓存只能自己来完整的实现。下面有几个方案。

## 一、自己实现的播放器
这种情况大多是根据下载来的数据解码播放，下载的时候做下缓存就好了

## 二、自带播放器+LocalServer
在iOS本地开启`Local Server`服务，然后`MPMoviePlayerController`请求本地`Local Server`服务。本地`Local Server`服务再不停的去对应的视频地址获取视频流。本地Local Server请求的时候，就可以把视频流缓存在本地。[Demo来源:Code4App](http://code4app.com/ios/视频边下载边播放/5292c381cb7e8445678b5ac2#)

## 三、AVPlayer+AVMutableComposition+AVAssetExportSession
原理是直接给`AVPlayer`传URL，让其内部自己去处理数据下载，然后通过`AVMutableComposition`和`AVAssetExportSession`从`AVAsset`提取视频的数据进行缓存。

### AVMutableComposition
> AVMutableComposition is a mutable subclass of AVComposition you use when you want to create a new composition from existing assets. You can add and remove tracks, and you can add, remove, and scale time ranges.

作用是从现有的`AVAsset`中创建出一个新的`AVComposition`，使用者能够从别的asset中提取他们的音频轨道或视频轨道，并且把它们添加到新建的composition中。

### AVAssetExportSession
> An AVAssetExportSession object transcodes the contents of an AVAsset source object to create an output of the form described by a specified export preset.

作用是把`AVAsset`解码输出到本地文件中。

关键需要把原先的`AVAsset(AVURLAsset)`实现的数据提取出来后拼接成另一个`AVAsset(AVComposition)`的数据然后解码输出，由于通过网络url下载下来的视频没有保存视频的原始数据（苹果没有暴露接口给我们获取），下载后播放的avasset不能使用`AVAssetExportSession`输出到本地文件，要曲线地把下载下来的视频通过重构成另外一个`AVAsset`实例才能输出。

``` //
NSString *documentDirectory = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES)[0];
NSString *myPathDocument = [documentDirectory stringByAppendingPathComponent:[NSString stringWithFormat:@"%@.mp4",[_source.videoUrl MD5]]];


NSURL *fileUrl = [NSURL fileURLWithPath:myPathDocument];

if (asset != nil) {
AVMutableComposition *mixComposition = [[AVMutableComposition alloc]init];
AVMutableCompositionTrack *firstTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo preferredTrackID:kCMPersistentTrackID_Invalid];
[firstTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, asset.duration) ofTrack:[[asset tracksWithMediaType:AVMediaTypeVideo]objectAtIndex:0] atTime:kCMTimeZero error:nil];

AVMutableCompositionTrack *audioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio preferredTrackID:kCMPersistentTrackID_Invalid];
[audioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, asset.duration) ofTrack:[[asset tracksWithMediaType:AVMediaTypeAudio]objectAtIndex:0] atTime:kCMTimeZero error:nil];

AVAssetExportSession *exporter = [[AVAssetExportSession alloc]initWithAsset:mixComposition presetName:AVAssetExportPresetHighestQuality];
exporter.outputURL = fileUrl;
if (exporter.supportedFileTypes) {
exporter.outputFileType = [exporter.supportedFileTypes objectAtIndex:0] ;
exporter.shouldOptimizeForNetworkUse = YES;
[exporter exportAsynchronouslyWithCompletionHandler:^{

}];

}
}
```


## 四、AVPlayer+AVAssetResourceLoader
> An AVAssetResourceLoader object mediates resource requests from an AVURLAsset object with a delegate object that you provide. When a request arrives, the resource loader asks your delegate if it is able to handle the request and reports the results back to the asset.
`AVAssetResourceLoader`协调来自`AVURLAsset`的资源请求，你需要实现它的`delegate`。当收到一个请求时，`ResourceLoader`询问你的`delegate`是否能处理并将结果返回给`asset`。
![AVPlayer和AVAssetResourceLoader的层次结构](http://oo8snaf4x.bkt.clouddn.com/15003581605281.jpg?imageView2/0/q/100)
`AVAssetResourceLoader`通过你提供的委托对象去调节`AVURLAsset`所需要的加载资源。而很重要的一点是，`AVAssetResourceLoader`仅在`AVURLAsset`不知道如何去加载这个URL资源时才会被调用，就是说你提供的委托对象在`AVURLAsset`不知道如何加载资源时才会得到调用。一般我们可以更改URL的scheme用来隐藏真实的URL。如：

``` //
NSURLComponents *components = [[NSURLComponents alloc] initWithURL:url resolvingAgainstBaseURL:NO];
components.scheme = kCacheScheme;
    
NSString *appendStr = components.query.length > 0 ? @"&" : @"?";
NSURL *assetURL = [NSURL URLWithString:[NSString stringWithFormat:@"%@%@MCurl=%@", components.URL.absoluteString, appendStr, url.absoluteString]];
```

`AVAssetResourceLoader`的`delegate`收到的是一个类型为`AVAssetResourceLoadingRequest`的请求。
> An AVAssetResourceLoadingRequest object encapsulates information about a resource request issued from a resource loader object.


| AVAssetResourceLoadingRequest | overview |
| --- | --- |
| request: URLRequest | 被我们修改后的URL(可以通过修改scheme把真实URL传过来) |
| contentInformationRequest: AVAssetResourceLoadingContentInformationRequest? | 查询视频的长度和格式，需要我们在收到数据后填入 |
| dataRequest: AVAssetResourceLoadingDataRequest? | 数据请求的范围 |

![](http://oo8snaf4x.bkt.clouddn.com/15003585179182.png?imageView2/0/q/100)
![](http://oo8snaf4x.bkt.clouddn.com/15006036617110.png?imageView2/0/q/100)




![](http://oo8snaf4x.bkt.clouddn.com/15006173795980.jpg?imageView2/0/q/100)
![](http://oo8snaf4x.bkt.clouddn.com/15006174492389.jpg?imageView2/0/q/100)

#### Seek后关键操作
- `NSURLRequest` 更改请求的范围

``` //
- (void)addValue:(NSString *)value forHTTPHeaderField:(NSString *)field; 
```

## [JPVideoPlayer](http://www.jianshu.com/p/66638bdfd537)
> 一个还不错的库，实现了简单的播放器，支持缓存，缓存管理等。
> 重大缺陷在不支持seek，如果加入seek对整个设计造成较大改动。
> [github](https://github.com/newyjp/JPVideoPlayer)

![框架图](http://oo8snaf4x.bkt.clouddn.com/15004311348817.png?imageView2/0/q/100)

其主要流程为：

- 传入URL，判断是否有缓存
- 有的话直接读文件播放
- 没有的话开下载
- 下载的数据缓存并写回`AVURLAsset`的请求
- 根据接收的数据大小和请求的数据大小判断文件完整性，完整则从临时文件夹移入完整文件夹

重要的细节在，当没有缓冲时，是直接拿URL去开下载，在第一次收到数据并写入缓存时才去设置`resourceloader`，根据`resourceloader`收到的`request`去缓存中拿数据写回，这就造成了seek后没法根据新的`request`去下载对应范围的数据(当然可以重写下载，但这样对整个框架会造成较大的改动)。
### JPVideoPlayerDownloaderOperation
`- URLSession:dataTask:didReceiveResponse:completionHandler;`
第一次请求拿到需要请求的数据expectedsize，判断是否有足够空间存储expectedsize

## Question

- 能不能异步多下载
- 播放器内部的请求机制 比如一次请求的数据播放完还是播放到一个阈值就开始下一次请求，这个请求范围又是什么
- seek后是立刻发出新请求，还是内部会有判断是否缓冲到了seek的位置
- seek后拿到range数据怎么去写，直接写在文件末尾seek到前面的数据再插入，还是直接能定位到文件中真正的位置写入

- 整体流程跑一遍
- `resourceLoader:shouldWaitForLoadingOfRequestedResource:`前的数据哪来的
拿到URL后直接异步开启下载，并异步保证线程安全的写入缓存文件。
`NSURLResponse`的结构 

``` //
{ URL: http://120.25.226.186:32812/resources/videos/minion_01.mp4 } 
{ status code: 200, headers {
    "Accept-Ranges" = bytes;
    "Content-Length" = 9071810;
    "Content-Type" = "video/mp4";
    Date = "Thu, 27 Jul 2017 06:37:58 GMT";
    Etag = "W/\"9071810-1409456092000\"";
    "Last-Modified" = "Sun, 31 Aug 2014 03:34:52 GMT";
    Server = "Apache-Coyote/1.1";
}}
```

- 播放器的数据请求包含哪些

``` //
AVAssetResourceLoadingRequest:
URL request = <NSMutableURLRequest: 0x61000000a090> { URL: SystemCannotRecognition:www.newpan.com }, 
request ID = 1, 
content information request = <AVAssetResourceLoadingContentInformationRequest: 0x618000009c10, 
content type = "(null)", 
content length = 0, 
byte range access supported = NO, 
disk caching permitted = NO, 
renewal date = (null)>, 

data request = <AVAssetResourceLoadingDataRequest: 0x60000000a180, 
requested offset = 0, 
requested length = 2, 
requests all data to end of resource = NO, 
current offset = 0>
```

- `resourceLoader:shouldWaitForLoadingOfRequestedResource:`的请求有没有被用到
`resourceLoader:shouldWaitForLoadingOfRequestedResource:`收到的请求被拿来去缓存文件中请求数据
- 怎么去缓存文件中拿数据响应should请求的
` AVAssetResourceLoadingDataRequest.respondWithData:`
- 网络没跟上，没拿到数据，怎么去判断，转菊花，又怎么判断有数据了
监听`AVPlayerItem`的属性`loadedTimeRanges`、`status`
- 文件读写的线程安全

``` //
dispatch_queue_t ioQueue;
@synchronized (self) {
    dispatch_async(ioQueue, ^{
        // write to file stream
    }
}
```

## [VIMediaCache](https://mp.weixin.qq.com/s?__biz=MzI5NzY3NjgzMQ==&mid=2247483655&idx=1&sn=dd4cfade9b24bd752cf2a77c1a5796d8&chksm=ecb03877dbc7b16146f4a0b79300264729b66d97d8acc737aaa6e1e34878959bfcf2167b0d6f&mpshare=1&scene=1&srcid=0720HyOUr7AGQrc0nxCQG7j6&key=0ebc3a09d7ac5a1df6ebbb20b82ce334f789ac2304dd02b45f0a934a41520b28e3ff0c3abfab979162f9b2b9f9e3c373f5dfb8faf273dc5a352abdee46305dec02ce1ebd1fe57db5211ed3aba13010b6&ascene=0&uin=NDE4MDM3MzYw&devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12.6+build(16G29)&version=12020810&nettype=WIFI&fontScale=100&pass_ticket=lIfTCCrYOxltP84AWwYjJKwof%2BoMM5CpzC0uJ%2BP1ltcRMrA7Fp6nFM27O3mwuYhm)
> 
> [github](https://github.com/vitoziv/VIMediaCache)
![框架图](media/15008224327487/15015025351439.jpg)


> 参考
> [iOS开发系列--音频播放、录音、视频播放、拍照、视频录制](http://www.cnblogs.com/kenshincui/p/4186022.html#video)
> [AVplayer实现播放本地和网络视频（Swift3.0）](http://blog.csdn.net/longshihua/article/details/53909733)
> [iOS视频流开发（2）—视频播放](http://www.cnblogs.com/zy1987/p/5028624.html)
> [iOS音频播放 (九)：边播边缓存](http://msching.github.io/blog/2016/05/24/audio-in-ios-9/)
> [iOS音视频实现边下载边播放](http://sky-weihao.github.io/2015/10/06/Video-streaming-and-caching-in-iOS/)
> [AVFoundation(二)：核心AVAsset](http://www.jianshu.com/p/9805be76ee68)
> [AVFoundation编程指南2-用AVPlayer播放视频](http://1199game.com/2016/10/avfoundation-2/)
> [AV Foundation系列（五）媒体组合](http://www.jianshu.com/p/c6be05ffe418)


